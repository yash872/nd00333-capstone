{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning using HyperDrive\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598531914256
    }
   },
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "import pandas as pd\n",
    "from azureml.core.workspace import Workspace\n",
    "from azureml.train.automl.run import AutoMLRun\n",
    "import time\n",
    "import logging\n",
    "from sklearn import datasets\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import requests\n",
    "import joblib\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import time\n",
    "import logging\n",
    "\n",
    "from azureml.core import Dataset, Workspace, Experiment\n",
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "\n",
    "\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core import Experiment\n",
    "from azureml.train.estimator import Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure ML Experiment Submission\n",
    "\n",
    "To use this notebook, you need to download config.json file from Azure ML Workspace and place it in this folder. This will allow us to get the workspace reference right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "try:\n",
    "    ws = Workspace.from_config()\n",
    "    print(ws.name, ws.location, ws.resource_group, ws.location, sep='\\t')\n",
    "    print('Library configuration succeeded')\n",
    "except:\n",
    "    print('Workspace not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "# Choose a name for your CPU cluster\n",
    "cluster_name = \"AUTOML-cluster\"\n",
    "\n",
    "# Verify that cluster does not exist already\n",
    "try:\n",
    "    cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D12_V2',\n",
    "                                                           max_nodes=5)\n",
    "    cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "cluster.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598531917374
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Creating daatset in a file\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "print('fetching MNIST data...')\n",
    "mnist = fetch_openml('mnist_784')\n",
    "mnist['target'] = np.array([int(x) for x in mnist['target']])\n",
    "\n",
    "# use a random subset of n records to reduce training time.\n",
    "n = 20000\n",
    "shuffle_index = np.random.permutation(70000)[:n]\n",
    "X, y = mnist['data'][shuffle_index], mnist['target'][shuffle_index]\n",
    "\n",
    "os.makedirs('dataset',exist_ok=True)\n",
    "with open('dataset/mnist.pkl','wb') as f:\n",
    "    pickle.dump((X,y),f)\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ws.get_default_datastore()\n",
    "ds.upload('./dataset', target_path='mnist_data', overwrite=True, show_progress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Training Script\n",
    "\n",
    "Created a Training Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile mytrain.py\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from azureml.core import Run\n",
    "from azureml.core.model import Model\n",
    "import pickle\n",
    "import keras\n",
    "from keras.layers import Dense,Dropout\n",
    "\n",
    "parser = argparse.ArgumentParser(description='MNIST Train')\n",
    "parser.add_argument('--data_folder', type=str, dest='data_folder', help='data folder mounting point')\n",
    "parser.add_argument('--epochs', type=int, default=3)\n",
    "parser.add_argument('--batch_size', type=int, default=128)\n",
    "parser.add_argument('--dropout', type=float)\n",
    "parser.add_argument('--hidden', type=int, default=100)\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "mnist_fn = os.path.join(args.data_folder, 'mnist_data','mnist.pkl')\n",
    "mnist_fn = 'dataset/mnist.pkl'\n",
    "with open(mnist_fn,'rb') as f:\n",
    "    X,y = pickle.load(f)\n",
    "\n",
    "X /= 255.0\n",
    "y = keras.utils.to_categorical(y,10)\n",
    "\n",
    "n = int(0.8*X.shape[0])\n",
    "x_train = X[0:n]\n",
    "y_train = y[0:n]\n",
    "x_test = X[n:]\n",
    "y_test = y[n:]\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(Dense(args.hidden,input_shape=(784,),activation='relu'))\n",
    "if args.dropout is not None and args.dropout<1:\n",
    "    model.add(Dropout(args.dropout))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=args.batch_size,\n",
    "          epochs=args.epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "\n",
    "os.makedirs('outputs',exist_ok=True)\n",
    "model.save('outputs/mnist_model.hdf5')\n",
    "\n",
    "# Log metrics\n",
    "run = Run.get_context()\n",
    "run.log('Test Loss', score[0])\n",
    "run.log('Accuracy', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperdrive Configuration\n",
    "\n",
    "TODO: Explain the model you are using and the reason for chosing the different hyperparameters, termination policy and config settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Keras-MNIST'\n",
    "exp = Experiment(workspace=ws, name=experiment_name)\n",
    "script_params = {\n",
    "                '--data_folder': ws.get_default_datastore(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = Estimator(source_directory='.',\n",
    "                script_params=script_params,\n",
    "                compute_target=cluster,\n",
    "                entry_script='mytrain.py',\n",
    "                pip_packages=['keras','tensorflow']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = exp.submit(estimator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598531923519
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Hyperparameter optimization using Hyperdrive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544893076
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.train.hyperdrive import *\n",
    "\n",
    "param_sampling = RandomParameterSampling({\n",
    "         '--hidden': choice([50,100,200,300]),\n",
    "         '--batch_size': choice([64,128]), \n",
    "         '--epochs': choice([5,10,50]),\n",
    "         '--dropout': choice([0.5,0.8,1])\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598544897941
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "early_termination_policy = MedianStoppingPolicy(evaluation_interval=1, delay_evaluation=0)\n",
    "hd_config = HyperDriveConfig(estimator=est,\n",
    "                            hyperparameter_sampling=param_sampling,\n",
    "                            policy=early_termination_policy,\n",
    "                            primary_metric_name='Accuracy',\n",
    "                            primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,\n",
    "                            max_total_runs=16,\n",
    "                            max_concurrent_runs=4)\n",
    "experiment = Experiment(workspace=ws, name='keras-hyperdrive')\n",
    "hyperdrive_run = experiment.submit(hd_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598544898497
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546648408
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# hyperdrive_run.cancel()\n",
    "from azureml.widgets import RunDetails\n",
    "RunDetails(hyperdrive_run).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the hyperdrive experiments and display all the properties of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546650307
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "best_run = hyperdrive_run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "print(best_run)\n",
    "print('Best accuracy: {}'.format(best_run_metrics['Accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598546657829
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "best_run.register_model(model_name='mnist_keras', model_path='outputs/mnist_model.hdf5')"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
